{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load indexes and normalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# where the data lives:\n",
    "\n",
    "path = \"~/data/LANL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load box/port info from json:\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "data = json.load(open(\"boxport_data.json\", 'r'))\n",
    "\n",
    "def jsonIntKeys(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {int(k):str(v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "def jsonIntVals(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {str(k):int(v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "box_index = jsonIntVals( data['box_indices'] )\n",
    "index_box = jsonIntKeys( data['indices_box'] )\n",
    "port_index = jsonIntVals( data['port_indices'] )\n",
    "index_port = jsonIntKeys( data['indices_port'] )\n",
    "\n",
    "bbox = set([re.sub('[\\\"\\n]+', \"\", s) for s in box_indices.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define netflow RDD - filter to boxes in 'bbox' (busy computers):\n",
    "\n",
    "flowfile = path + \"flows.csv\"\n",
    "flows = sc.textFile(flowfile).map(lambda line: [str(x) for x in line.split(',')])\n",
    "\n",
    "def filt(x):\n",
    "    return [int(x[0]), int(x[1]), x[2], x[3], x[4], x[5], int(x[6]), int(x[7]), int(x[8])]\n",
    "\n",
    "subflows = flows.filter(lambda f: f[2] in bbox and f[4] in bbox).map(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 9501, 138, 2205, 122, 1, 3, 12],\n",
       " [1, 0, 2244, 122, 8986, 122, 1, 2, 9],\n",
       " [1, 0, 2244, 122, 8986, 122, 1, 2, 9],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 8986, 122, 2244, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2244, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2408, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2408, 122, 1, 2, 8]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define normalisation mapping to be readable in Keras:\n",
    "\n",
    "from math import log, floor\n",
    "\n",
    "protocols = [1,6,17,41]\n",
    "proto_index = dict((c, i) for i, c in enumerate(protocols))\n",
    "index_proto = dict((i, c) for i, c in enumerate(protocols))\n",
    "\n",
    "def logbin(x):\n",
    "    return int(floor(log(x, 2)))\n",
    "\n",
    "def normal_port(x):\n",
    "    if re.match('^N', x)!=None: \n",
    "        return 'N' \n",
    "    else: \n",
    "        return x\n",
    "\n",
    "def normalise(x):\n",
    "    return [x[0], \n",
    "            logbin(x[1]+1),\n",
    "            box_indices[x[2]],\n",
    "            port_indices[normal_port(x[3])],\n",
    "            box_indices[x[4]],\n",
    "            port_indices[normal_port(x[5])],\n",
    "            proto_index[x[6]], \n",
    "            logbin(x[7]), \n",
    "            logbin(x[8])]\n",
    "\n",
    "# check:\n",
    "subflows.map(normalise).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the schema is:\n",
    "\n",
    "<ul>\n",
    "<li> timestamp\n",
    "<li> duration (log)\n",
    "<li> source computer\n",
    "<li> source port\n",
    "<li> destination computer\n",
    "<li> destination port\n",
    "<li> protocol\n",
    "<li> nr packets (log)\n",
    "<li> nr bytes (log)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set input vector sizes:\n",
    "\n",
    "lg_duration = 7\n",
    "lg_packets = 22\n",
    "lg_bytes = 32\n",
    "nr_proto = 4\n",
    "nr_box = len(indices_box)   # 10109\n",
    "nr_port = len(indices_port) #   326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)            (None, 100)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)            (None, 100, 512)    5120000     main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "aux_input (InputLayer)             (None, 5)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                      (None, 32)          69760       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                    (None, 37)          0           lstm_2[0][0]                     \n",
      "                                                                   aux_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                    (None, 64)          2432        merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)                 (None, 1)           33          lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)                (None, 1)           65          dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 5192290\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, merge\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "lstm_out = LSTM(32)(x)\n",
    "auxiliary_loss = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = merge([lstm_out, auxiliary_input], mode='concat')\n",
    "\n",
    "# we stack a deep fully-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# and finally we add the main logistic regression layer\n",
    "main_loss = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "model = Model(input=[main_input, auxiliary_input], output=[main_loss, auxiliary_loss])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
