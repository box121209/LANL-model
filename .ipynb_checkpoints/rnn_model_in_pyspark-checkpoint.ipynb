{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load indexes and normalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# where the data lives:\n",
    "\n",
    "path = \"/Users/wmoxbury/data/LANL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load box/port info from json:\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "data = json.load(open(\"boxport_data.json\", 'r'))\n",
    "\n",
    "def jsonIntKeys(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {int(k):str(v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "def jsonIntVals(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {str(k):int(v) for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "box_index = jsonIntVals( data['box_indices'] )\n",
    "index_box = jsonIntKeys( data['indices_box'] )\n",
    "port_index = jsonIntVals( data['port_indices'] )\n",
    "index_port = jsonIntKeys( data['indices_port'] )\n",
    "\n",
    "bbox = set([re.sub('[\\\"\\n]+', \"\", s) for s in box_index.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define netflow RDD - filter to boxes in 'bbox' (busy computers):\n",
    "\n",
    "flowfile = path + \"flows.csv\"\n",
    "flows = sc.textFile(flowfile).map(lambda line: [str(x) for x in line.split(',')])\n",
    "\n",
    "def filt(x):\n",
    "    return [int(x[0]), int(x[1]), x[2], x[3], x[4], x[5], int(x[6]), int(x[7]), int(x[8])]\n",
    "\n",
    "subflows = flows.filter(lambda f: f[2] in bbox and f[4] in bbox).map(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 9501, 138, 2205, 122, 1, 3, 12],\n",
       " [1, 0, 2244, 122, 8986, 122, 1, 2, 9],\n",
       " [1, 0, 2244, 122, 8986, 122, 1, 2, 9],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 5354, 122, 9484, 0, 1, 0, 5],\n",
       " [1, 0, 8986, 122, 2244, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2244, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2408, 122, 1, 2, 8],\n",
       " [1, 0, 8986, 122, 2408, 122, 1, 2, 8]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define normalisation mapping to be readable in Keras:\n",
    "\n",
    "from math import log, floor\n",
    "\n",
    "protocols = [1,6,17,41]\n",
    "proto_index = dict((c, i) for i, c in enumerate(protocols))\n",
    "index_proto = dict((i, c) for i, c in enumerate(protocols))\n",
    "\n",
    "def logbin(x):\n",
    "    return int(floor(log(x, 2)))\n",
    "\n",
    "def normal_port(x):\n",
    "    if re.match('^N', x)!=None: \n",
    "        return 'N' \n",
    "    else: \n",
    "        return x\n",
    "\n",
    "def normalise(x):\n",
    "    return [x[0], \n",
    "            logbin(x[1]+1),\n",
    "            box_index[x[2]],\n",
    "            port_index[normal_port(x[3])],\n",
    "            box_index[x[4]],\n",
    "            port_index[normal_port(x[5])],\n",
    "            proto_index[x[6]], \n",
    "            logbin(x[7]), \n",
    "            logbin(x[8])]\n",
    "\n",
    "# check:\n",
    "subflows.map(normalise).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the schema is:\n",
    "\n",
    "<ul>\n",
    "<li> timestamp\n",
    "<li> duration (log)\n",
    "<li> source computer\n",
    "<li> source port\n",
    "<li> destination computer\n",
    "<li> destination port\n",
    "<li> protocol\n",
    "<li> nr packets (log)\n",
    "<li> nr bytes (log)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set input vector sizes:\n",
    "\n",
    "lg_duration = 7\n",
    "lg_packets = 22\n",
    "lg_bytes = 32\n",
    "nr_proto = 4\n",
    "nr_box = len(index_box)   # 10109\n",
    "nr_port = len(index_port) #   326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "bytes (InputLayer)                 (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dst_pt (InputLayer)                (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "duration (InputLayer)              (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "packets (InputLayer)               (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "proto (InputLayer)                 (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "src_pt (InputLayer)                (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dst_input (InputLayer)             (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)            (None, 32, 128)     41728       src_pt[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)            (None, 32, 128)     41728       dst_pt[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)            (None, 32, 2)       8           proto[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)            (None, 32, 4)       28          duration[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)            (None, 32, 8)       176         packets[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)            (None, 32, 16)      512         bytes[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "next_src (InputLayer)              (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "src_input (InputLayer)             (None, 32)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)            (None, 32, 256)     2587904     src_input[0][0]                  \n",
      "                                                                   dst_input[0][0]                  \n",
      "                                                                   next_src[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                    (None, 32, 286)     0           embedding_2[0][0]                \n",
      "                                                                   embedding_3[0][0]                \n",
      "                                                                   embedding_4[0][0]                \n",
      "                                                                   embedding_5[0][0]                \n",
      "                                                                   embedding_6[0][0]                \n",
      "                                                                   embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                    (None, 32, 1054)    0           merge_1[0][0]                    \n",
      "                                                                   embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "                                                                   embedding_1[2][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 32, 512)     3209216     merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                      (None, 512)         2099200     lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 512)         0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "bytes_output (Dense)               (None, 32)          16416       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dst_port_output (Dense)            (None, 326)         167238      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "duration_output (Dense)            (None, 7)           3591        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "next_dst (Dense)                   (None, 256)         131328      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "packets_output (Dense)             (None, 22)          11286       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "proto_output (Dense)               (None, 4)           2052        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "src_port_output (Dense)            (None, 326)         167238      dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 8479649\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import merge\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "# hyperparameters:\n",
    "nhidden = [512, 512]\n",
    "unroll = 32\n",
    "embed_dim = 256\n",
    "dropout_W = 0.2 # input gates\n",
    "dropout_U = 0.2 # recurrent connections\n",
    "\n",
    "# netflow inputs:\n",
    "src_input = Input(shape=(unroll,), dtype='int32', name='src_input')\n",
    "dst_input = Input(shape=(unroll,), dtype='int32', name='dst_input')\n",
    "src_pt_input = Input(shape=(unroll,), dtype='int32', name='src_pt')\n",
    "dst_pt_input = Input(shape=(unroll,), dtype='int32', name='dst_pt')\n",
    "proto_input = Input(shape=(unroll,), dtype='int32', name='proto')\n",
    "duration_input = Input(shape=(unroll,), dtype='int32', name='duration')\n",
    "packets_input = Input(shape=(unroll,), dtype='int32', name='packets')\n",
    "bytes_input = Input(shape=(unroll,), dtype='int32', name='bytes')\n",
    "\n",
    "# shared embedding for computer feeds:\n",
    "comp_encoding = Embedding(output_dim=embed_dim, input_dim=nr_box, input_length=unroll)\n",
    "src = comp_encoding(src_input)\n",
    "dst = comp_encoding(dst_input)\n",
    "\n",
    "# other embeddings:\n",
    "src_pt = Embedding(output_dim=128, input_dim=nr_port, input_length=unroll)(src_pt_input)\n",
    "dst_pt = Embedding(output_dim=128, input_dim=nr_port, input_length=unroll)(dst_pt_input)\n",
    "proto = Embedding(output_dim=2, input_dim=nr_proto, input_length=unroll)(proto_input)\n",
    "duration = Embedding(output_dim=4, input_dim=lg_duration, input_length=unroll)(duration_input)\n",
    "packets = Embedding(output_dim=8, input_dim=lg_packets, input_length=unroll)(packets_input)\n",
    "bytes = Embedding(output_dim=16, input_dim=lg_bytes, input_length=unroll)(bytes_input)\n",
    "\n",
    "# merge:\n",
    "data_merged = merge([src_pt, dst_pt, proto, duration, packets, bytes], mode='concat')\n",
    "\n",
    "# add src computer for next time-step, as a query stream to train on:\n",
    "next_src = Input(shape=(unroll,), dtype='int32', name='next_src')\n",
    "query = comp_encoding(next_src)\n",
    "\n",
    "# pass data and query to RNN layers:\n",
    "inner = merge([data_merged, src, dst, query], mode='concat')\n",
    "for i in range(len(nhidden)-1):\n",
    "    inner = LSTM(nhidden[i], return_sequences=True, dropout_U=dropout_U, dropout_W=dropout_W)(inner)\n",
    "inner = LSTM(nhidden[-1], return_sequences=False, dropout_U=dropout_U, dropout_W=dropout_W)(inner)\n",
    "inner = Dropout(dropout_W)(inner)\n",
    "\n",
    "# add softmax outputs:\n",
    "proto_output = Dense(4, activation='softmax', name='proto_output')(inner)\n",
    "duration_output = Dense(lg_duration, activation='softmax', name='duration_output')(inner)\n",
    "packets_output = Dense(lg_packets, activation='softmax', name='packets_output')(inner)\n",
    "bytes_output = Dense(lg_bytes, activation='softmax', name='bytes_output')(inner)\n",
    "src_port_output = Dense(nr_port, activation='softmax', name='src_port_output')(inner)\n",
    "dst_port_output = Dense(nr_port, activation='softmax', name='dst_port_output')(inner)\n",
    "\n",
    "# add dst computer output:\n",
    "next_dst = Dense(embed_dim, activation='relu', name='next_dst')(inner)\n",
    "\n",
    "# put it all together:\n",
    "model = Model(input=[src_input,\n",
    "                     dst_input,\n",
    "                     src_pt_input,\n",
    "                     dst_pt_input,\n",
    "                     proto_input,\n",
    "                     duration_input,\n",
    "                     packets_input, \n",
    "                     bytes_input,\n",
    "                     next_src], \n",
    "              output=[proto_output,\n",
    "                      duration_output,\n",
    "                      packets_output,\n",
    "                      bytes_output,\n",
    "                      src_port_output,\n",
    "                      dst_port_output,\n",
    "                      next_dst])\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss=['categorical_crossentropy' for i in range(6)] + ['mse'],\n",
    "              loss_weights=[0.5, 1., 1., 1., 2., 2., 4.])\n",
    "\n",
    "# ...and summarise:\n",
    "model.summary()\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 100\n",
    "train = np.array( subflows.map(normalise).take(N+1) )\n",
    "\n",
    "def make_input_vectors(z, mx, unroll=unroll):\n",
    "    n = len(z)\n",
    "    X = np.zeros((n - unroll, unroll), dtype='float32')\n",
    "    for i in range(n - unroll):\n",
    "        X[i,:] = z[i: i + unroll]\n",
    "    return X\n",
    "\n",
    "src_in = make_input_vectors(train[range(N), 2], nr_box)\n",
    "dst_in = make_input_vectors(train[range(N), 4], nr_box)\n",
    "src_pt_in = make_input_vectors(train[range(N), 3], nr_port)\n",
    "dst_pt_in = make_input_vectors(train[range(N), 5], nr_port)\n",
    "proto_in = make_input_vectors(train[range(N), 6], nr_proto)\n",
    "duration_in = make_input_vectors(train[range(N), 1], lg_duration)\n",
    "packets_in = make_input_vectors(train[range(N), 7], lg_packets)\n",
    "bytes_in = make_input_vectors(train[range(N),8], lg_bytes)\n",
    "next_src_in = make_input_vectors(train[range(1,N+1),2], nr_box)\n",
    "\n",
    "input = [src_in, dst_in, src_pt_in, dst_pt_in, proto_in, duration_in, packets_in, bytes_in, next_src_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "Cast uint8 to bool is not supported\n\t [[Node: Cast = Cast[DstT=DT_BOOL, SrcT=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_keras_learning_phase_0)]]\nCaused by op u'Cast', defined at:\n  File \"/Developer/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Developer/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-6f9ec0ed86b7>\", line 46, in <module>\n    inner = LSTM(nhidden[i], return_sequences=True, dropout_U=dropout_U, dropout_W=dropout_W)(inner)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 485, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 543, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 148, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 218, in call\n    constants = self.get_constants(x)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 770, in get_constants\n    B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 802, in in_train_phase\n    x = tf.python.control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 300, in cast\n    return gen_math_ops.cast(x, dtype, name=name)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 193, in cast\n    return _op_def_lib.apply_op(\"Cast\", x=x, DstT=DstT, name=name)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-270ceb13c888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#wts = model.get_weights()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Developer/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1124\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Developer/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Developer/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         raise errors._make_specific_exception(node_def, op, e.error_message,\n\u001b[0;32m--> 419\u001b[0;31m                                               e.code)\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Cast uint8 to bool is not supported\n\t [[Node: Cast = Cast[DstT=DT_BOOL, SrcT=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_keras_learning_phase_0)]]\nCaused by op u'Cast', defined at:\n  File \"/Developer/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Developer/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Developer/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-6f9ec0ed86b7>\", line 46, in <module>\n    inner = LSTM(nhidden[i], return_sequences=True, dropout_U=dropout_U, dropout_W=dropout_W)(inner)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 485, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 543, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/engine/topology.py\", line 148, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 218, in call\n    constants = self.get_constants(x)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 770, in get_constants\n    B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]\n  File \"/Developer/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 802, in in_train_phase\n    x = tf.python.control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 300, in cast\n    return gen_math_ops.cast(x, dtype, name=name)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 193, in cast\n    return _op_def_lib.apply_op(\"Cast\", x=x, DstT=DstT, name=name)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Developer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# the following works in theano but gives an error with tensorflow...\n",
    "\n",
    "#input\n",
    "output = model.predict(input, batch_size=1)\n",
    "#wts = model.get_weights()\n",
    "\n",
    "#print([y.shape for y in output])\n",
    "#print(output[0][1:10])\n",
    "#print([w.shape for w in wts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10109, 256)\n"
     ]
    }
   ],
   "source": [
    "# of particular interest is the shared computer encoding, which will also be needed in the loss function:\n",
    "cmp_code = wts[6]\n",
    "\n",
    "print(cmp_code.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_onehot(x, n):\n",
    "    N = len(x)-unroll\n",
    "    out = np.zeros([N,n])\n",
    "    for i in range(1,N):\n",
    "        out[i, x[i]] = 1\n",
    "    return out\n",
    "\n",
    "proto_tgt = make_onehot(train[range(1,N+1), 6], nr_proto)\n",
    "duration_tgt = make_onehot(train[range(1,N+1), 1], lg_duration)\n",
    "packets_tgt = make_onehot(train[range(1,N+1), 7], lg_packets)\n",
    "bytes_tgt = make_onehot(train[range(1,N+1),8], lg_bytes)\n",
    "src_pt_tgt = make_onehot(train[range(1,N+1), 3], nr_port)\n",
    "dst_pt_tgt = make_onehot(train[range(1,N+1), 5], nr_port)\n",
    "\n",
    "def make_nextdst(x, cmp_code):\n",
    "    N = len(x)-unroll\n",
    "    out = np.zeros([N, embed_dim])\n",
    "    for i in range(N):\n",
    "        out[i,:] = cmp_code[x[i],:]\n",
    "    return out\n",
    "\n",
    "dst_tgt = make_nextdst(train[range(1,N+1), 4], cmp_code)\n",
    "target = [proto_tgt, duration_tgt, packets_tgt, bytes_tgt, src_pt_tgt, dst_pt_tgt, dst_tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "68/68 [==============================] - 2s - loss: 9.5224 - proto_output_loss: 0.4381 - duration_output_loss: 1.6515 - packets_output_loss: 1.8058 - bytes_output_loss: 2.0822 - src_port_output_loss: 0.8965 - dst_port_output_loss: 0.9822 - next_dst_loss: 0.0017     \n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 2s - loss: 9.7147 - proto_output_loss: 0.5011 - duration_output_loss: 1.4584 - packets_output_loss: 1.7878 - bytes_output_loss: 2.2740 - src_port_output_loss: 0.8741 - dst_port_output_loss: 1.0945 - next_dst_loss: 0.0017     \n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 2s - loss: 9.3499 - proto_output_loss: 0.5290 - duration_output_loss: 1.4222 - packets_output_loss: 1.6573 - bytes_output_loss: 2.1265 - src_port_output_loss: 1.0272 - dst_port_output_loss: 0.9096 - next_dst_loss: 0.0014     \n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 2s - loss: 8.6026 - proto_output_loss: 0.4292 - duration_output_loss: 1.4319 - packets_output_loss: 1.5784 - bytes_output_loss: 2.0473 - src_port_output_loss: 0.7766 - dst_port_output_loss: 0.8860 - next_dst_loss: 0.0013     \n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 2s - loss: 8.9653 - proto_output_loss: 0.4474 - duration_output_loss: 1.5659 - packets_output_loss: 1.6687 - bytes_output_loss: 2.0947 - src_port_output_loss: 0.7943 - dst_port_output_loss: 0.9093 - next_dst_loss: 0.0013     \n"
     ]
    }
   ],
   "source": [
    "# model fitting -- after each epoch, reset the target dst using the updated computer embedding matrix:\n",
    "\n",
    "nr_epochs = 5\n",
    "\n",
    "for i in range(nr_epochs):\n",
    "    cmp_code = model.get_weights()[6]\n",
    "    target[6] = make_nextdst(train[range(1,N+1), 4], cmp_code)\n",
    "    model.fit(input, target, nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
